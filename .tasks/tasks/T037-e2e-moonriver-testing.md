---
id: T037
title: End-to-End Testing on Moonriver Testnet (50+ Nodes, Full Slot Generation)
status: pending
priority: 1
agent: fullstack
dependencies: [T001, T002, T003, T004, T005, T006, T007, T009, T010, T011, T028, T029, T035]
blocked_by: []
created: 2025-12-24T00:00:00Z
updated: 2025-12-24T00:00:00Z
tags: [testing, e2e, moonriver, integration, phase1]

context_refs:
  - context/project.md
  - context/architecture.md

docs_refs:
  - PRD Section 29 (Success Criteria - Moonriver Phase 1)
  - PRD Section 6 (Deployment Phases)

est_tokens: 9000
actual_tokens: null
---

## Description

Execute comprehensive end-to-end testing on Moonriver testnet with 10+ participant nodes simulating the full ICN protocol: stake ICN tokens â†’ elect directors â†’ generate AI video via Vortex â†’ achieve BFT consensus â†’ distribute video via P2P â†’ update reputation â†’ handle challenges/disputes. Validates entire system under real-world network conditions before mainnet launch.

**Test Objectives:**
1. Verify runtime upgrade deployed successfully to Moonriver
2. Simulate 10+ nodes (3 Directors, 3 Super-Nodes, 4 Viewers)
3. Complete 10+ slot generations end-to-end
4. Test challenge/dispute mechanism with intentional fraud
5. Verify P2P video distribution to all viewers
6. Measure glass-to-glass latency (<45s target)
7. Load test BFT coordination (target: 50 TPS on-chain events)

**Success Criteria (from PRD):**
- All pallets operational on Moonriver
- 10+ test nodes participating
- Complete staking â†’ election â†’ reputation â†’ BFT flow
- Video distribution working

## Acceptance Criteria

- [ ] Moonriver runtime upgrade proposal submitted and enacted
- [ ] 10+ test accounts funded with DEV tokens (Moonriver testnet)
- [ ] 3 Director nodes running with GPU (RTX 3060+)
- [ ] 3 Super-Node instances deployed (erasure storage configured)
- [ ] 4 Viewer nodes connected to P2P mesh
- [ ] 10+ successful slot generations completed
- [ ] All generated videos verified via CLIP (score >0.75)
- [ ] BFT consensus reached in â‰¥8/10 slots
- [ ] At least 1 challenge successfully resolved (fraud detected and slashed)
- [ ] Video distributed to all viewers within 30s of generation
- [ ] Glass-to-glass latency measured: average <45s, P99 <60s
- [ ] Reputation scores updated correctly for all participants
- [ ] No critical errors in logs (panic, segfault, OOM)
- [ ] TPS load test: 50 on-chain events/second sustained for 5 minutes
- [ ] Prometheus metrics collected for all nodes
- [ ] Test report generated with performance data

## Test Scenarios

**Test Case 1: Runtime Deployment and Initialization**
- Given: Moonriver testnet access, runtime WASM built
- When: Submit `sudo.sudoUncheckedWeight(system.setCode)` extrinsic
- Then: Runtime upgrade succeeds, all pallets callable, no storage migration errors

**Test Case 2: Multi-Account Staking**
- Given: 10 test accounts with 1000 DEV each
- When: Each account stakes 100-500 ICN with different roles (Director/SuperNode/Validator)
- Then: Stakes recorded on-chain, roles assigned correctly, regional distribution enforced

**Test Case 3: Director Election and Cooldown**
- Given: 5 Directors staked across 3 regions
- When: Advance to slot 100
- Then: Exactly 5 directors elected, no more than 2 from same region, cooldown prevents re-election for 20 slots

**Test Case 4: Full Slot Generation**
- Given: 5 Directors elected for slot 200
- When: Recipe published to GossipSub topic `/icn/recipes/1.0.0`
- Then:
  1. All 5 Directors receive recipe within 2s
  2. Vortex generates video in <15s
  3. CLIP verification scores >0.75 for all
  4. BFT coordination via gRPC completes in <10s
  5. 3+ Directors agree on canonical embedding hash
  6. Canonical Director submits BFT result to Moonriver
  7. Super-Nodes download video chunks within 5s
  8. Viewers receive video within 30s

**Test Case 5: BFT Challenge (Fraud Detection)**
- Given: Slot 250 completed with BFT result
- When: Challenger detects fraudulent result (CLIP score <0.60), submits challenge with 25 ICN bond
- Then:
  1. Challenge recorded on-chain with 50-block deadline
  2. Validators provide attestations
  3. Challenge upheld (majority validators disagree with result)
  4. Directors slashed 100 ICN each
  5. Challenger refunded 25 ICN + 10 ICN reward
  6. Reputation updated (-200 for directors, +50 for challenger)

**Test Case 6: Video Distribution Hierarchy**
- Given: Canonical video generated by Director
- When: Video published to P2P network
- Then:
  1. Super-Nodes (Tier 1) download within 5s
  2. Regional Relays (Tier 2) download from Super-Nodes within 10s
  3. Viewers (Tier 3) download from Relays within 20s
  4. Total propagation time <30s

**Test Case 7: Reputation Decay and Updates**
- Given: Directors and Validators with reputation scores >500
- When: 2 weeks pass with no activity
- Then: Reputation decays 10% per week (compounding), on-chain storage reflects updated scores

**Test Case 8: Load Test - 50 TPS**
- Given: 10+ nodes active
- When: Submit 50 reputation events/second for 5 minutes (15,000 total events)
- Then: All events processed, Moonriver handles load, block times stable (~6s), no timeouts

**Test Case 9: NAT Traversal (Real Network Conditions)**
- Given: Viewers behind NAT (home routers)
- When: Viewers attempt P2P connections
- Then: STUN â†’ UPnP â†’ Circuit Relay fallback succeeds, all viewers connected

**Test Case 10: Graceful Degradation (Node Failure)**
- Given: 5 Directors elected, 1 Director node crashes
- When: BFT coordination continues with 4 remaining Directors
- Then: Consensus reached with 3-of-4 agreement, system continues operating

## Technical Implementation

**File:** `scripts/moonriver-e2e-test.sh`

```bash
#!/bin/bash
set -euo pipefail

MOONRIVER_WS="wss://wss.api.moonriver.moonbeam.network"
DIRECTOR_COUNT=3
SUPER_NODE_COUNT=3
VIEWER_COUNT=4
SLOT_COUNT=10

echo "ðŸ§ª ICN End-to-End Testing on Moonriver"
echo "========================================"

# Step 1: Deploy runtime
echo "1ï¸âƒ£ Deploying runtime to Moonriver..."
./scripts/submit-runtime-upgrade.sh \
  --network moonriver \
  --wasm target/wasm32-unknown-unknown/release/moonbeam_runtime.wasm \
  --sudo-seed "$MOONRIVER_SUDO_KEY"

# Step 2: Fund test accounts
echo "2ï¸âƒ£ Funding test accounts..."
for i in $(seq 1 10); do
  ./scripts/fund-account.sh "//TestAccount$i" 1000
done

# Step 3: Start Director nodes
echo "3ï¸âƒ£ Starting $DIRECTOR_COUNT Director nodes..."
for i in $(seq 1 $DIRECTOR_COUNT); do
  docker run -d --name director-$i --gpus all \
    -e SUBSTRATE_WS_URL=$MOONRIVER_WS \
    -e STAKING_KEY="$(cat keys/director-$i.key)" \
    ghcr.io/icn/director:latest
done

# Step 4: Start Super-Nodes
echo "4ï¸âƒ£ Starting $SUPER_NODE_COUNT Super-Nodes..."
for i in $(seq 1 $SUPER_NODE_COUNT); do
  docker run -d --name super-node-$i \
    -e SUBSTRATE_WS_URL=$MOONRIVER_WS \
    -e STAKING_KEY="$(cat keys/super-node-$i.key)" \
    ghcr.io/icn/super-node:latest
done

# Step 5: Start Viewer nodes
echo "5ï¸âƒ£ Starting $VIEWER_COUNT Viewer nodes..."
for i in $(seq 1 $VIEWER_COUNT); do
  docker run -d --name viewer-$i \
    -p $((3000 + i)):3000 \
    ghcr.io/icn/viewer:latest
done

# Step 6: Wait for nodes to connect
echo "6ï¸âƒ£ Waiting for P2P mesh to form..."
sleep 30

# Step 7: Stake and delegate
echo "7ï¸âƒ£ Staking accounts..."
./scripts/stake-all-accounts.sh

# Step 8: Trigger slot generations
echo "8ï¸âƒ£ Generating $SLOT_COUNT slots..."
for slot in $(seq 1 $SLOT_COUNT); do
  echo "   Slot $slot..."
  ./scripts/publish-recipe.sh recipes/test-recipe-$slot.json

  # Wait for slot completion
  timeout 60s ./scripts/wait-for-bft-result.sh $slot || {
    echo "   âŒ Slot $slot failed to complete"
    exit 1
  }

  echo "   âœ… Slot $slot completed"
done

# Step 9: Trigger challenge
echo "9ï¸âƒ£ Testing challenge mechanism..."
./scripts/submit-challenge.sh --slot 5 --evidence-hash 0xdeadbeef

# Step 10: Collect metrics
echo "ðŸ”Ÿ Collecting performance metrics..."
./scripts/collect-metrics.sh > test-results/metrics.json

# Step 11: Generate report
echo "ðŸ“Š Generating test report..."
./scripts/generate-e2e-report.sh

echo ""
echo "âœ… End-to-end testing complete!"
echo "   Report: test-results/e2e-report.html"
```

**File:** `scripts/wait-for-bft-result.sh`

```bash
#!/bin/bash
set -euo pipefail

SLOT=$1
MOONRIVER_WS="wss://wss.api.moonriver.moonbeam.network"

echo "Waiting for BFT result for slot $SLOT..."

for i in {1..60}; do
  result=$(polkadot-js-api query.icnDirector.bftResults $SLOT)

  if [[ "$result" != "null" ]]; then
    echo "âœ… BFT result received for slot $SLOT"
    exit 0
  fi

  sleep 1
done

echo "âŒ Timeout waiting for BFT result"
exit 1
```

**File:** `scripts/generate-e2e-report.sh`

```bash
#!/bin/bash
set -euo pipefail

METRICS_FILE="test-results/metrics.json"
REPORT_FILE="test-results/e2e-report.html"

# Parse metrics
total_slots=$(jq '.total_slots' $METRICS_FILE)
successful_slots=$(jq '.successful_slots' $METRICS_FILE)
avg_latency=$(jq '.avg_glass_to_glass_latency_sec' $METRICS_FILE)
p99_latency=$(jq '.p99_glass_to_glass_latency_sec' $METRICS_FILE)
bft_success_rate=$(jq '.bft_success_rate' $METRICS_FILE)

# Generate HTML report
cat > $REPORT_FILE <<EOF
<!DOCTYPE html>
<html>
<head>
  <title>ICN Moonriver E2E Test Report</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 40px; }
    .metric { margin: 20px 0; }
    .pass { color: green; font-weight: bold; }
    .fail { color: red; font-weight: bold; }
  </style>
</head>
<body>
  <h1>ICN Moonriver E2E Test Report</h1>
  <p>Generated: $(date)</p>

  <h2>Results Summary</h2>
  <div class="metric">
    <strong>Total Slots:</strong> $total_slots
  </div>
  <div class="metric">
    <strong>Successful Slots:</strong> $successful_slots / $total_slots
    <span class="$([ $successful_slots -ge 8 ] && echo 'pass' || echo 'fail')">
      ($(echo "scale=1; $successful_slots * 100 / $total_slots" | bc)%)
    </span>
  </div>
  <div class="metric">
    <strong>Average Latency:</strong> ${avg_latency}s
    <span class="$(awk 'BEGIN { exit ('$avg_latency' < 45) ? 0 : 1 }' && echo 'pass' || echo 'fail')">
      (Target: <45s)
    </span>
  </div>
  <div class="metric">
    <strong>P99 Latency:</strong> ${p99_latency}s
    <span class="$(awk 'BEGIN { exit ('$p99_latency' < 60) ? 0 : 1 }' && echo 'pass' || echo 'fail')">
      (Target: <60s)
    </span>
  </div>
  <div class="metric">
    <strong>BFT Success Rate:</strong> ${bft_success_rate}%
    <span class="$(awk 'BEGIN { exit ('$bft_success_rate' >= 80) ? 0 : 1 }' && echo 'pass' || echo 'fail')">
      (Target: â‰¥80%)
    </span>
  </div>

  <h2>Conclusion</h2>
  <p class="$([ $successful_slots -ge 8 ] && [ $(awk 'BEGIN { print ('$avg_latency' < 45) }') -eq 1 ] && echo 'pass' || echo 'fail')">
    $([ $successful_slots -ge 8 ] && [ $(awk 'BEGIN { print ('$avg_latency' < 45) }') -eq 1 ] && echo 'âœ… PASS - Ready for mainnet' || echo 'âŒ FAIL - Needs optimization')
  </p>
</body>
</html>
EOF

echo "Report generated: $REPORT_FILE"
```

### Validation Commands

```bash
# Run full E2E test
./scripts/moonriver-e2e-test.sh

# Run single slot test
./scripts/publish-recipe.sh recipes/test.json
./scripts/wait-for-bft-result.sh 1

# Check node status
docker ps | grep icn

# View logs
docker logs director-1 --tail 100

# Collect metrics
./scripts/collect-metrics.sh

# Generate report
./scripts/generate-e2e-report.sh
open test-results/e2e-report.html
```

## Dependencies

**Hard Dependencies:**
- [T001] Moonbeam Fork Setup
- [T002-T007] All pallets implemented
- [T009-T011] Off-chain node implementations
- [T028] Local dev environment (for testing scripts)
- [T029] Director Docker image
- [T035] Integration tests (validates components work)

**External Dependencies:**
- Moonriver testnet access
- DEV tokens for testing (faucet)
- Cloud VMs for 10+ nodes (or community volunteers)
- 3 GPUs (RTX 3060+) for Directors

## Design Decisions

**Decision 1: 10 Nodes vs. 50 Nodes for Initial Test**
- **Rationale:** 10 nodes sufficient to validate protocol, easier to coordinate, lower cost
- **Trade-offs:** (+) Manageable, cost-effective. (-) Doesn't test full-scale network

**Decision 2: Moonriver vs. Local Testnet**
- **Rationale:** Moonriver provides real network conditions (latency, censorship, NAT)
- **Trade-offs:** (+) Realistic. (-) Higher costs, slower iteration

## Risks & Mitigations

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Runtime upgrade rejected by governance | High | Low | Engage Moonriver community early, provide clear rationale |
| Insufficient GPU capacity | High | Medium | Use cloud GPU instances (AWS g4dn, GCP A10) |
| Network partitions during testing | Medium | Medium | Test with 3 geographically distributed nodes |
| BFT fails to reach consensus | High | Low | Extensive local testing first (T035), fallback to 2-of-5 threshold |

## Progress Log

### [2025-12-24] - Task Created
**Dependencies:** T001-T007, T009-T011, T028, T029, T035

## Completion Checklist

- [ ] Moonriver runtime deployed
- [ ] 10+ nodes running (3 Directors, 3 Super-Nodes, 4 Viewers)
- [ ] 10+ slots generated successfully
- [ ] Glass-to-glass latency measured (<45s avg)
- [ ] Challenge mechanism tested
- [ ] TPS load test passed (50 events/sec)
- [ ] Test report generated

**Definition of Done:**
End-to-end testing on Moonriver demonstrates full ICN protocol with 10+ nodes, 10+ successful slot generations, glass-to-glass latency <45s average, BFT consensus rate â‰¥80%, and challenge mechanism validated with real fraud detection and slashing.
