# LivePortrait FP16 Configuration
# Model configuration for audio-driven video warping with 3.5GB VRAM budget

model:
  name: "liveportrait-base-fp16"
  source: "huggingface"  # or "github" for custom builds
  repo_id: "liveportrait/base-fp16"  # Hypothetical Hugging Face model ID

  # Precision settings
  precision: "fp16"  # torch.float16
  compute_dtype: "float16"

  # VRAM budget
  vram_budget_gb: 3.5
  vram_min_gb: 3.0
  vram_max_gb: 4.0

# Performance optimization
optimization:
  use_tensorrt: true  # Enable TensorRT if available (20-30% speedup)
  tensorrt_engine_path: "~/.cache/vortex/liveportrait_trt.engine"
  batch_size: 1  # Sequential frame generation (batching uses too much VRAM)
  num_workers: 0  # No multiprocessing (GPU-bound)

# Video output settings
output:
  fps: 24  # Cinema standard frame rate
  resolution: [512, 512]  # Height × Width (matches Flux actor input)
  max_duration_sec: 45  # Maximum video duration per slot
  format: "TCHW"  # Tensor format: Time × Channels × Height × Width

# Audio settings
audio:
  sample_rate: 24000  # 24kHz mono (matches Kokoro output)
  frame_duration_ms: 41.67  # ~42ms per frame at 24fps (1000ms / 24fps)
  lookahead_frames: 2  # Lookahead for smoother lip-sync

# Expression presets
expressions:
  neutral:
    intensity: 0.3
    eye_openness: 0.5
    mouth_scale: 1.0
    head_motion: 0.2
    description: "Minimal expression, calm demeanor"

  excited:
    intensity: 0.8
    eye_openness: 0.8
    mouth_scale: 1.2
    head_motion: 0.6
    description: "Energetic, wide eyes, animated gestures"

  manic:
    intensity: 1.0
    eye_openness: 0.9
    mouth_scale: 1.3
    head_motion: 0.8
    description: "Maximum energy, Rick-like enthusiasm"

  calm:
    intensity: 0.2
    eye_openness: 0.4
    mouth_scale: 0.9
    head_motion: 0.1
    description: "Subdued, low energy, minimal movement"

# Lip-sync settings
lipsync:
  viseme_dim: 3  # [jaw_open, lip_width, lip_rounding]
  phoneme_to_viseme_mapping:
    # Vowels
    - phonemes: ["AA", "AH", "AO"]  # a, ah, aw
      viseme: [0.8, 0.6, 0.3]  # Wide open jaw, neutral lips
    - phonemes: ["EH", "AE"]  # e, a
      viseme: [0.5, 0.7, 0.2]  # Half open jaw, wide lips
    - phonemes: ["IH", "IY"]  # i, ee
      viseme: [0.3, 0.8, 0.1]  # Small jaw, wide lips
    - phonemes: ["UH", "UW"]  # u, oo
      viseme: [0.4, 0.4, 0.8]  # Medium jaw, rounded lips
    - phonemes: ["ER"]  # er
      viseme: [0.4, 0.5, 0.4]  # Medium jaw, neutral

    # Consonants
    - phonemes: ["B", "P", "M"]  # Bilabials
      viseme: [0.1, 0.3, 0.9]  # Closed lips, rounded
    - phonemes: ["F", "V"]  # Labiodentals
      viseme: [0.2, 0.5, 0.3]  # Small opening, lip-teeth contact
    - phonemes: ["TH", "DH"]  # Dentals
      viseme: [0.3, 0.6, 0.2]  # Tongue visible
    - phonemes: ["T", "D", "N", "L"]  # Alveolars
      viseme: [0.3, 0.5, 0.3]  # Neutral
    - phonemes: ["K", "G", "NG"]  # Velars
      viseme: [0.4, 0.5, 0.3]  # Back of mouth
    - phonemes: ["CH", "JH", "SH", "ZH"]  # Affricates/fricatives
      viseme: [0.3, 0.4, 0.4]  # Slight rounding
    - phonemes: ["S", "Z"]  # Sibilants
      viseme: [0.2, 0.6, 0.2]  # Narrow opening
    - phonemes: ["R"]  # Rhotic
      viseme: [0.4, 0.4, 0.5]  # Rounded
    - phonemes: ["W", "Y"]  # Glides
      viseme: [0.3, 0.5, 0.6]  # Slight rounding
    - phonemes: ["H"]  # Glottal
      viseme: [0.4, 0.5, 0.3]  # Neutral open

  # Smoothing parameters
  smoothing_window: 3  # frames
  transition_speed: 0.5  # 0 = instant, 1 = very smooth

  # Accuracy target
  alignment_tolerance_frames: 2  # ±2 frames (~83ms at 24fps)

# Expression sequence transitions
transitions:
  interpolation: "cubic"  # "linear", "cubic", "ease-in-out"
  keyframe_duration_sec: 11.25  # 45s / 4 expressions = 11.25s each
  blend_duration_sec: 1.0  # Transition blend time between expressions

# Model weights cache
cache:
  directory: "~/.cache/vortex/liveportrait"
  weights_filename: "liveportrait_fp16.safetensors"
  tensorrt_filename: "liveportrait_trt.engine"
  download_source: "https://huggingface.co/liveportrait/base-fp16/resolve/main/model.safetensors"

# Performance targets
performance:
  target_latency_p99_sec: 8.0  # P99 generation time for 45s video on RTX 3060
  target_throughput_fps: 135  # 1080 frames / 8 seconds = 135 fps generation
  warmup_iterations: 3  # Warmup runs to stabilize CUDA kernels

# Monitoring
monitoring:
  enable_vram_tracking: true
  log_frame_generation_time: false  # Too verbose, disable in production
  alert_on_vram_spike: true
  vram_spike_threshold_gb: 0.5  # Alert if VRAM increases by >500MB
